{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline  \n",
    "import powerlaw\n",
    "import csv\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "import sys\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "\n",
    "PUBYEAR_MIN = 1996\n",
    "PUBYEAR_MAX = 2017\n",
    "\n",
    "CITEYEAR_MAX = 2017\n",
    "\n",
    "eid_info_dir = \"../DATA/output/docinfo/eid_source_pubdate/\"\n",
    "eid_info_files = glob.glob(eid_info_dir + \"*.txt\")\n",
    "\n",
    "pubyear_dict = {}\n",
    "srcid_dict = {}\n",
    "srcid_asjc = {}\n",
    "\n",
    "_MAX_PROCESS = 8\n",
    "\n",
    "\n",
    "def flatList(tdlist):\n",
    "    templist = []\n",
    "    for i in tdlist:\n",
    "        templist += i\n",
    "    return templist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nowfile in eid_info_files:\n",
    "    with open(nowfile, 'rb') as csvfile: \n",
    "        reader = csv.reader(csvfile, delimiter='\\t') \n",
    "        for row in reader: \n",
    "            if(row[1].isdigit()):\n",
    "                pubyear_dict[row[0]] = int(row[1])\n",
    "                srcid_dict[row[0]] = row[2]\n",
    "gc.collect()\n",
    "\n",
    "print len(pubyear_dict), len(srcid_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_info_file = \"../DATA/SCOPUS_SCIMAGO_MAPPING_DATA/src_final.txt\"\n",
    "\n",
    "with open(source_info_file, 'rb') as csvfile: \n",
    "    reader = csv.reader(csvfile, delimiter='\\t') \n",
    "    for row in reader:\n",
    "        srcid_asjc[row[0]] = row[5].split(\";\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PArrayLength = PUBYEAR_MAX - PUBYEAR_MIN + 1\n",
    "CArrayLength = CITEYEAR_MAX - PUBYEAR_MIN + 1\n",
    "\n",
    "network_info_dir = \"../DATA/output/network/separated/\"\n",
    "network_info_files = glob.glob(network_info_dir + \"*.txt\")\n",
    "print len(network_info_files)\n",
    "\n",
    "CountArray = []\n",
    "for i in range(PArrayLength):\n",
    "    temparray = []\n",
    "    for j in range(CArrayLength):\n",
    "        temparray.append({})\n",
    "    CountArray.append(temparray)\n",
    "\n",
    "SrcCountArray = []\n",
    "for i in range(PArrayLength):\n",
    "    temparray = []\n",
    "    for j in range(CArrayLength):\n",
    "        temparray.append({})\n",
    "    SrcCountArray.append(temparray)\n",
    "\n",
    "SrcPaperArray = []\n",
    "for i in range(PArrayLength):\n",
    "    SrcPaperArray.append({})    \n",
    "    \n",
    "ASJCCountArray = []\n",
    "for i in range(PArrayLength):\n",
    "    temparray = []\n",
    "    for j in range(CArrayLength):\n",
    "        temparray.append({})\n",
    "    ASJCCountArray.append(temparray)\n",
    "\n",
    "gc.collect()\n",
    "count_exist = 0\n",
    "for k, v in pubyear_dict.iteritems():\n",
    "    if(k not in srcid_dict):\n",
    "        continue\n",
    "    elif(srcid_dict[k] not in srcid_asjc):\n",
    "        continue\n",
    "    elif(v > PUBYEAR_MAX or v < PUBYEAR_MIN):\n",
    "        continue\n",
    "    SrcPaperArray[v - PUBYEAR_MIN][srcid_dict[k]] = (SrcPaperArray[v - PUBYEAR_MIN]).setdefault(srcid_dict[k], 0) + 1        \n",
    "    for nC in range(v - PUBYEAR_MIN, CArrayLength):\n",
    "        count_exist += 1\n",
    "        for asjcid in srcid_asjc[ srcid_dict[k] ]:\n",
    "            ASJCCountArray[v - PUBYEAR_MIN][nC][asjcid] = 0\n",
    "        CountArray[v - PUBYEAR_MIN][nC][k] = 0\n",
    "        SrcCountArray[v - PUBYEAR_MIN][nC][srcid_dict[k]] = 0       \n",
    "\n",
    "print \"STEP2\"\n",
    "print count_exist\n",
    "count_err = 0\n",
    "\n",
    "for nowfile in network_info_files:\n",
    "    with open(nowfile, 'rb') as csvfile: \n",
    "        reader = csv.reader(csvfile, delimiter='\\t') \n",
    "        for row in reader: \n",
    "            if(row[0] not in srcid_dict or row[1] not in srcid_dict):\n",
    "                pass\n",
    "            elif(srcid_dict[row[0]] not in srcid_asjc or srcid_dict[row[1]] not in srcid_asjc):\n",
    "                pass\n",
    "            elif(pubyear_dict[row[0]] > PUBYEAR_MAX or pubyear_dict[row[0]] < PUBYEAR_MIN):\n",
    "                pass\n",
    "            elif(pubyear_dict[row[1]] > CITEYEAR_MAX):\n",
    "                pass\n",
    "            elif(pubyear_dict[row[1]] < pubyear_dict[row[0]]):\n",
    "                count_err += 1 \n",
    "            else:\n",
    "                nP = pubyear_dict[row[0]] - PUBYEAR_MIN\n",
    "                nC = pubyear_dict[row[1]] - PUBYEAR_MIN\n",
    "                CountArray[nP][nC][row[0]] += 1\n",
    "                for asjcid in srcid_asjc[ srcid_dict[row[0]] ]:\n",
    "                    ASJCCountArray[nP][nC][asjcid] += 1\n",
    "                SrcCountArray[nP][nC][srcid_dict[row[0]]] += 1                \n",
    "\n",
    "for i in range(PArrayLength):\n",
    "    for j in range(CArrayLength):\n",
    "        for key, val in CountArray[i][j].iteritems():\n",
    "            try:\n",
    "                CountArray[i][j][key] = float(val*SrcPaperArray[i][srcid_dict[k]])/float(SrcCountArray[i][j][srcid_dict[key]])\n",
    "            except ZeroDivisionError: CountArray[i][j][key] = 0\n",
    "\n",
    "gc.collect()\n",
    "print count_err            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_out = open('../DATA/distribution_compare_scrid_normalized/all_merged.txt', \"w\")\n",
    "\n",
    "for i in range(PArrayLength):\n",
    "    f_out.write(\"\\n\")\n",
    "    for j in range(CArrayLength):\n",
    "        data = sorted(CountArray[i][j].values(), reverse=True)\n",
    "        if(len(data) < 2 or j < i):\n",
    "            f_out.write(\"\\t\".join(str(x) for x in [i+PUBYEAR_MIN, j+PUBYEAR_MIN, len(data)])+ \"\\t-1\\t0\\t0\\t0\\t0\\t0\\t0\\n\")\n",
    "            continue\n",
    "        pl = powerlaw.Fit(data, descrete = True)\n",
    "        likelihood_list = []\n",
    "        likelihood_list.append(np.sum(pl.power_law.loglikelihoods(data)))\n",
    "        likelihood_list.append(np.sum(pl.truncated_power_law.loglikelihoods(data)))\n",
    "        likelihood_list.append(np.sum(pl.lognormal.loglikelihoods(data)))\n",
    "        likelihood_list.append(np.sum(pl.lognormal_positive.loglikelihoods(data)))\n",
    "        likelihood_list.append(np.sum(pl.exponential.loglikelihoods(data)))\n",
    "        likelihood_list.append(np.sum(pl.stretched_exponential.loglikelihoods(data)))\n",
    "        f_out.write(\"\\t\".join(str(x) for x in [i+PUBYEAR_MIN, j+PUBYEAR_MIN, len(data), likelihood_list.index(max(likelihood_list))])+\"\\t\" \n",
    "                    + \"\\t\".join(str(x) for x in likelihood_list) + \"\\n\")\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "def PowerLawASJC(code):\n",
    "    if(not code.isdigit()):\n",
    "        return -1\n",
    "    outfile = \"../DATA/distribution_compare_scrid_normalized/ASJC_\" + str(code) + \".txt\"\n",
    "    print outfile\n",
    "    f_out = open(outfile, \"w\")\n",
    "    for i in range(PArrayLength):\n",
    "        f_out.write(\"\\n\")\n",
    "        for j in range(CArrayLength):\n",
    "            data = []\n",
    "            for key, val in CountArray[i][j].iteritems():\n",
    "                if(key not in srcid_dict):\n",
    "                    continue\n",
    "                elif(srcid_dict[key] not in srcid_asjc):\n",
    "                    continue\n",
    "                SourceID = srcid_dict[key]\n",
    "                SourceASJC = srcid_asjc[SourceID]\n",
    "                if(code in SourceASJC):\n",
    "                    data.append(val)\n",
    "            data = sorted(data, reverse=True)\n",
    "            if(len(data) < 2 or j < i):\n",
    "                f_out.write(\"\\t\".join(str(x) for x in [i+PUBYEAR_MIN, j+PUBYEAR_MIN, len(data)])+ \"\\t-1\\t0\\t0\\t0\\t0\\t0\\t0\\n\")\n",
    "                continue\n",
    "            pl = powerlaw.Fit(data, descrete = True)\n",
    "            likelihood_list = []\n",
    "            likelihood_list.append(np.sum(pl.power_law.loglikelihoods(data)))\n",
    "            likelihood_list.append(np.sum(pl.truncated_power_law.loglikelihoods(data)))\n",
    "            likelihood_list.append(np.sum(pl.lognormal.loglikelihoods(data)))\n",
    "            likelihood_list.append(np.sum(pl.lognormal_positive.loglikelihoods(data)))\n",
    "            likelihood_list.append(np.sum(pl.exponential.loglikelihoods(data)))\n",
    "            likelihood_list.append(np.sum(pl.stretched_exponential.loglikelihoods(data)))\n",
    "            f_out.write(\"\\t\".join(str(x) for x in [i+PUBYEAR_MIN, j+PUBYEAR_MIN, len(data), likelihood_list.index(max(likelihood_list))])+\"\\t\" \n",
    "                        + \"\\t\".join(str(x) for x in likelihood_list) + \"\\n\")\n",
    "    f_out.close()   \n",
    "    return 0\n",
    "\n",
    "oldstderr = sys.stderr\n",
    "sys.stderr = open('log.txt', 'w')\n",
    "               \n",
    "\n",
    "print type(srcid_asjc.values())\n",
    "listASJC = set(flatList(srcid_asjc.values()))\n",
    "\n",
    "print listASJC \n",
    "\n",
    "p = Pool(processes=_MAX_PROCESS)\n",
    "tempout = p.map(PowerLawASJC, listASJC)\n",
    "p.close()\n",
    "        \n",
    "sys.stderr = oldstderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PowerLawASJC2(code):\n",
    "    if(not code.isdigit()):\n",
    "        return -1\n",
    "    outfile = \"../DATA/distribution_compare_scrid_normalized/ASJC_\" + str(code) + \".txt\"\n",
    "    print outfile\n",
    "    f_out = open(outfile, \"w\")\n",
    "    for i in range(PArrayLength):\n",
    "        f_out.write(\"\\n\")\n",
    "        for j in range(CArrayLength):\n",
    "            data = []\n",
    "            for key, val in CountArray[i][j].iteritems():\n",
    "                if(key not in srcid_dict):\n",
    "                    continue\n",
    "                elif(srcid_dict[key] not in srcid_asjc):\n",
    "                    continue\n",
    "                SourceID = srcid_dict[key]\n",
    "                SourceASJC = [x[:2] for x in srcid_asjc[SourceID]]\n",
    "                if(code in SourceASJC):\n",
    "                    data.append(val)\n",
    "            data = sorted(data)\n",
    "            if(len(data) < 2 or j < i):\n",
    "                f_out.write(\"\\t\".join(str(x) for x in [i+PUBYEAR_MIN, j+PUBYEAR_MIN, len(data)])+ \"\\t-1\\t0\\t0\\t0\\t0\\t0\\t0\\n\")\n",
    "                continue\n",
    "            pl = powerlaw.Fit(data, descrete = True);\n",
    "            likelihood_list = []\n",
    "            likelihood_list.append(np.sum(pl.power_law.loglikelihoods(data)))\n",
    "            likelihood_list.append(np.sum(pl.truncated_power_law.loglikelihoods(data)))\n",
    "            likelihood_list.append(np.sum(pl.lognormal.loglikelihoods(data)))\n",
    "            likelihood_list.append(np.sum(pl.lognormal_positive.loglikelihoods(data)))\n",
    "            likelihood_list.append(np.sum(pl.exponential.loglikelihoods(data)))\n",
    "            likelihood_list.append(np.sum(pl.stretched_exponential.loglikelihoods(data)))\n",
    "            #print likelihood_list\n",
    "            #print i+PUBYEAR_MIN, j+PUBYEAR_MIN, \n",
    "            f_out.write(\"\\t\".join(str(x) for x in [i+PUBYEAR_MIN, j+PUBYEAR_MIN, len(data), likelihood_list.index(max(likelihood_list))])+\"\\t\" \n",
    "                        + \"\\t\".join(str(x) for x in likelihood_list) + \"\\n\")\n",
    "    return 0\n",
    "\n",
    "listASJC2 = set(x[:2] for x in flatList(srcid_asjc.values()))\n",
    "\n",
    "p = Pool(processes=_MAX_PROCESS)\n",
    "tempout = p.map(PowerLawASJC2, listASJC2)\n",
    "p.close()\n",
    "\n",
    "f_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
